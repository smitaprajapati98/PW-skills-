{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "517b8f8e-4df2-4b23-b1b0-5f628b1883a7",
   "metadata": {},
   "source": [
    "# Q1. A company conducted a survey of its employees and found that 70% of the employees use the company's health insurance plan, while 40% of the employees who use the plan are smokers. What is the probability that an employee is a smoker given that he/she uses the health insurance plan?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33220a82-10bf-418c-826f-d2216874641e",
   "metadata": {},
   "source": [
    "- To find the probability that an employee is a smoker given that he/she uses the health insurance plan, we can use Bayes' theorem.\n",
    "\n",
    "Let:\n",
    "- A be the event that an employee uses the health insurance plan,\n",
    "- B be the event that an employee is a smoker.\n",
    "\n",
    "We are given:\n",
    "- \\( P(A) = 0.70 \\) (probability that an employee uses the health insurance plan),\n",
    "- \\( P(B|A) = 0.40 \\) (probability that an employee is a smoker given that they use the health insurance plan).\n",
    "\n",
    "We want to find \\( P(B|A) \\), the probability that an employee is a smoker given that they use the health insurance plan.\n",
    "\n",
    "Using Bayes' theorem:\n",
    "\\[ P(B|A) = \\frac{P(A|B) \\times P(B)}{P(A)} \\]\n",
    "\n",
    "Given that \\( P(B|A) \\times P(A) = P(A|B) \\times P(B) \\), we can rearrange the formula as:\n",
    "\\[ P(B|A) = \\frac{P(A|B) \\times P(B)}{P(A)} = \\frac{0.40 \\times P(B)}{0.70} \\]\n",
    "\n",
    "We know that \\( P(B) = \\frac{P(B \\cap A)}{P(A)} \\), where \\( P(B \\cap A) \\) is the probability that an employee is both a smoker and uses the health insurance plan.\n",
    "\n",
    "Given \\( P(B \\cap A) = P(B|A) \\times P(A) = 0.40 \\times 0.70 \\), we can calculate \\( P(B) \\) as:\n",
    "\\[ P(B) = \\frac{0.40 \\times 0.70}{0.70} \\]\n",
    "\n",
    "Therefore, the probability that an employee is a smoker given that he/she uses the health insurance plan is:\n",
    "\\[ P(B|A) = \\frac{0.40 \\times 0.70}{0.70} = 0.40 \\]\n",
    "\n",
    "So, the probability that an employee is a smoker given that he/she uses the health insurance plan is 0.40 or 40%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3948e92-9b06-4d91-9760-930b4c8b4c88",
   "metadata": {},
   "source": [
    "# Q2. What is the difference between Bernoulli Naive Bayes and Multinomial Naive Bayes?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea28da10-580c-447b-98e0-7463d2eae519",
   "metadata": {},
   "source": [
    "- Bernoulli Naive Bayes and Multinomial Naive Bayes are two variants of the Naive Bayes classifier, each suitable for different types of data.\n",
    "\n",
    "1. **Bernoulli Naive Bayes:**\n",
    "   - Assumes that features are binary-valued (e.g., presence or absence of a feature).\n",
    "   - Commonly used for text classification tasks where the presence or absence of words is used as features.\n",
    "   - It models the presence or absence of each term in the document, but not the frequency of terms.\n",
    "\n",
    "2. **Multinomial Naive Bayes:**\n",
    "   - Assumes that features represent counts (e.g., word counts in text classification).\n",
    "   - Suitable for text classification where the frequency of each term matters.\n",
    "   - It models the frequency of each term in the document, which can provide more information than just presence or absence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0121f50-0cbe-487e-89fd-ac2918b1e5d8",
   "metadata": {},
   "source": [
    "# Q3. How does Bernoulli Naive Bayes handle missing values?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b27c8596-f1b9-4770-a69a-5325db8593da",
   "metadata": {},
   "source": [
    "- In Bernoulli Naive Bayes, missing values are typically handled by ignoring them during the calculation of probabilities. Since Bernoulli Naive Bayes assumes that features are binary-valued (i.e., present or absent), missing values can be treated as if the feature is absent for that instance.\n",
    "\n",
    "- When computing the likelihood of a class given the features, the algorithm considers only the features that are present and ignores the missing values. This approach is based on the assumption that the absence of evidence (missing value) is not evidence of absence (the feature not being present).\n",
    "\n",
    "- In practical terms, when implementing Bernoulli Naive Bayes, missing values can be represented as a separate category (e.g., a third category alongside 0 and 1 for binary features) or simply ignored when calculating probabilities. The exact handling may depend on the implementation and the specific requirements of the problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b679b7f7-46dc-42f2-bb3a-8b0fea1fbd79",
   "metadata": {},
   "source": [
    "# Q4. Can Gaussian Naive Bayes be used for multi-class classification?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f17c026-6367-4003-a4ac-c81dca65e232",
   "metadata": {},
   "source": [
    "- Yes, Gaussian Naive Bayes can be used for multi-class classification. In Gaussian Naive Bayes, it is assumed that the features follow a normal (Gaussian) distribution. This assumption allows us to model the likelihood of each feature value given the class using the probability density function of the normal distribution.\n",
    "\n",
    "- For multi-class classification, Gaussian Naive Bayes can be extended to handle multiple classes by calculating the likelihood of each class for a given instance and then selecting the class with the highest likelihood as the predicted class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ce3a50-2989-4543-ab04-739ffbc5610b",
   "metadata": {},
   "source": [
    "# Q5. Assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5d116a7-d3e7-485b-b88a-796b32d895b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB, GaussianNB\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44e9b706-ac70-49a1-8f95-dcd97d7a58fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pip install ucimlrepo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e603806c-1952-491b-b58b-212902d453ab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'uci_id': 53, 'name': 'Iris', 'repository_url': 'https://archive.ics.uci.edu/dataset/53/iris', 'data_url': 'https://archive.ics.uci.edu/static/public/53/data.csv', 'abstract': 'A small classic dataset from Fisher, 1936. One of the earliest known datasets used for evaluating classification methods.\\n', 'area': 'Biology', 'tasks': ['Classification'], 'characteristics': ['Tabular'], 'num_instances': 150, 'num_features': 4, 'feature_types': ['Real'], 'demographics': [], 'target_col': ['class'], 'index_col': None, 'has_missing_values': 'no', 'missing_values_symbol': None, 'year_of_dataset_creation': 1936, 'last_updated': 'Tue Sep 12 2023', 'dataset_doi': '10.24432/C56C76', 'creators': ['R. A. Fisher'], 'intro_paper': {'title': 'The Iris data set: In search of the source of virginica', 'authors': 'A. Unwin, K. Kleinman', 'published_in': 'Significance, 2021', 'year': 2021, 'url': 'https://www.semanticscholar.org/paper/4599862ea877863669a6a8e63a3c707a787d5d7e', 'doi': '1740-9713.01589'}, 'additional_info': {'summary': 'This is one of the earliest datasets used in the literature on classification methods and widely used in statistics and machine learning.  The data set contains 3 classes of 50 instances each, where each class refers to a type of iris plant.  One class is linearly separable from the other 2; the latter are not linearly separable from each other.\\n\\nPredicted attribute: class of iris plant.\\n\\nThis is an exceedingly simple domain.\\n\\nThis data differs from the data presented in Fishers article (identified by Steve Chadwick,  spchadwick@espeedaz.net ).  The 35th sample should be: 4.9,3.1,1.5,0.2,\"Iris-setosa\" where the error is in the fourth feature. The 38th sample: 4.9,3.6,1.4,0.1,\"Iris-setosa\" where the errors are in the second and third features.  ', 'purpose': 'N/A', 'funded_by': None, 'instances_represent': 'Each instance is a plant', 'recommended_data_splits': None, 'sensitive_data': None, 'preprocessing_description': None, 'variable_info': None, 'citation': None}}\n",
      "           name     role         type demographic  \\\n",
      "0  sepal length  Feature   Continuous        None   \n",
      "1   sepal width  Feature   Continuous        None   \n",
      "2  petal length  Feature   Continuous        None   \n",
      "3   petal width  Feature   Continuous        None   \n",
      "4         class   Target  Categorical        None   \n",
      "\n",
      "                                         description units missing_values  \n",
      "0                                               None    cm             no  \n",
      "1                                               None    cm             no  \n",
      "2                                               None    cm             no  \n",
      "3                                               None    cm             no  \n",
      "4  class of iris plant: Iris Setosa, Iris Versico...  None             no  \n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "from ucimlrepo import fetch_ucirepo \n",
    "  \n",
    "# fetch dataset \n",
    "iris = fetch_ucirepo(id=53) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "X = iris.data.features \n",
    "y = iris.data.targets \n",
    "  \n",
    "# metadata \n",
    "print(iris.metadata) \n",
    "  \n",
    "# variable information \n",
    "print(iris.variables) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8056f1b-8ab5-4774-abc9-57d40b93a68f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7ff4bc4-c848-4c97-9c1f-ad042db559d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize the classifiers\n",
    "bernoulli_nb = BernoulliNB()\n",
    "multinomial_nb = MultinomialNB()\n",
    "gaussian_nb = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b7b9110-9a11-4124-8985-3f80f19bad18",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Perform 10-fold cross-validation\n",
    "accuracy_bernoulli = cross_val_score(bernoulli_nb, X, y, cv=10, scoring='accuracy').mean()\n",
    "precision_bernoulli = cross_val_score(bernoulli_nb, X, y, cv=10, scoring='precision_macro').mean()\n",
    "recall_bernoulli = cross_val_score(bernoulli_nb, X, y, cv=10, scoring='recall_macro').mean()\n",
    "f1_score_bernoulli = cross_val_score(bernoulli_nb, X, y, cv=10, scoring='f1_macro').mean()\n",
    "\n",
    "accuracy_multinomial = cross_val_score(multinomial_nb, X, y, cv=10, scoring='accuracy').mean()\n",
    "precision_multinomial = cross_val_score(multinomial_nb, X, y, cv=10, scoring='precision_macro').mean()\n",
    "recall_multinomial = cross_val_score(multinomial_nb, X, y, cv=10, scoring='recall_macro').mean()\n",
    "f1_score_multinomial = cross_val_score(multinomial_nb, X, y, cv=10, scoring='f1_macro').mean()\n",
    "\n",
    "accuracy_gaussian = cross_val_score(gaussian_nb, X, y, cv=10, scoring='accuracy').mean()\n",
    "precision_gaussian = cross_val_score(gaussian_nb, X, y, cv=10, scoring='precision_macro').mean()\n",
    "recall_gaussian = cross_val_score(gaussian_nb, X, y, cv=10, scoring='recall_macro').mean()\n",
    "f1_score_gaussian = cross_val_score(gaussian_nb, X, y, cv=10, scoring='f1_macro').mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9c5240eb-4ca7-4e01-9122-97a76c79ecbb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bernoulli Naive Bayes:\n",
      "Accuracy: 0.8839380364047911\n",
      "Precision: 0.8861178734839884\n",
      "Recall: 0.8719428323765064\n",
      "F1 Score: 0.8770092395078783\n",
      "\n",
      "Multinomial Naive Bayes:\n",
      "Accuracy: 0.7863496180326323\n",
      "Precision: 0.7798120406006364\n",
      "Recall: 0.7750390539916573\n",
      "F1 Score: 0.7757368439847935\n",
      "\n",
      "Gaussian Naive Bayes:\n",
      "Accuracy: 0.8217730830896915\n",
      "Precision: 0.8355405680394657\n",
      "Recall: 0.8454293399090297\n",
      "F1 Score: 0.8203085549230952\n"
     ]
    }
   ],
   "source": [
    "# Report the results\n",
    "print(\"Bernoulli Naive Bayes:\")\n",
    "print(\"Accuracy:\", accuracy_bernoulli)\n",
    "print(\"Precision:\", precision_bernoulli)\n",
    "print(\"Recall:\", recall_bernoulli)\n",
    "print(\"F1 Score:\", f1_score_bernoulli)\n",
    "\n",
    "print(\"\\nMultinomial Naive Bayes:\")\n",
    "print(\"Accuracy:\", accuracy_multinomial)\n",
    "print(\"Precision:\", precision_multinomial)\n",
    "print(\"Recall:\", recall_multinomial)\n",
    "print(\"F1 Score:\", f1_score_multinomial)\n",
    "\n",
    "print(\"\\nGaussian Naive Bayes:\")\n",
    "print(\"Accuracy:\", accuracy_gaussian)\n",
    "print(\"Precision:\", precision_gaussian)\n",
    "print(\"Recall:\", recall_gaussian)\n",
    "print(\"F1 Score:\", f1_score_gaussian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b6dd28-6201-408b-a49d-1b3265c8efcc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df627cd7-8889-4ade-b70e-bf11f2e2f716",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
